# 了解什么是爬虫

爬虫/网络爬虫(web crawler) 有时也叫网络蜘蛛(spider)，是一种用来获取万维网(world wide web) 内容的互联网机器人 (Internet bot)，常用于制作网页索引(web indexing)。更多信息可参考网页 https://en.wikipedia.org/wiki/Web_crawler

爬虫本质上是一种程序，它获取网页内容的行为类似人浏览网页。因为爬虫是程序，故在获取内容的效率上大大高于人手操作；通过并发的方式甚至可以构建更高效率的“分布式”爬虫，用于大规模的内容抓取。

# 了解爬虫的工作原理

网络爬虫使用一个URL列表，抓取URL所指向的网页内容，列表中的URL也叫“种子”。网络爬虫在爬取网页的过程中，会把网页中所有的“超链接”添加到这个URL列表中。网络爬虫下载到网页内容后，即可对该内容做处理，可以把这些内容存起来（归档）方便后续浏览检索（搜索引擎），或者只提取网页中的一部分内容。

# 了解网页快照的特点

用于存放网页归档的地方也叫“仓库” (repository)，里面所存放的文件也叫“网页快照”。仓库只存放html文本文档，而且仅存放html文档的最新版本。如果仓库存储的文件数量较大，则爬虫在一段时间之内能够更新的只是仓库中的一部分文件；互联网上的网页变化更新很快，造成仓库中的部分内容在服务器上对应的文件可能已经被更新或者被删除。

# 了解影响爬虫行为的一些策略

一系列的“策略”决定了爬虫的行为，这些策略有：

选择策略，决定需要下载的网页。互联网上的网页浩如烟海，而带宽和时间是有限的，因此爬虫需要对这些网页做筛选。爬虫可能只需要下载html网页，因此可以对URL按照内容类型做筛选，比如说只下载以.html, .htm, .php, .jsp, .asp, 或者斜杠结束的URL；这样的策略可能会造成大量的html网页被忽略。爬虫可以使用“网址标准化”方法来去除重复的URL，网址标准化方法包括把网址转换成小写，删除. （点）和.. （点点），等等。路径上移爬取 (path-ascending crawling) 法用于尽可能多地爬取指定网站的内容，比如说，给定一个网址http://llama.org/hamster/monkey/page.html，爬虫将会尝试下载 /hamster/monkey/page.html, /hamster/monkey/，/hamster/, /；此法对爬取被隔离的或者不被引用的资源非常有效。主题爬取 (focused crawling) 法用于爬取内容相似的网页，此法通常依赖搜索引擎来获取某一主题的相关URL，作为“种子”。

重新访问策略，决定检查网页是否有更新的时机。互联网上的内容瞬息万变，爬完给定的某一块内容可以消耗几周甚至几月的时间，在这几周或者几月的时间里，许多事情会发生，这些事情包括网页的创建，修改，和删除。用于决定是否需要重新访问网页的指标中，最常用的是“新鲜度” (freshness) 和“年龄” (age)；给定一个时间点，当线上网页的内容与本地仓库中的内容相同时，本地网页是新鲜的，否则就是不新鲜的；给定一个时间点t，本地网页的年龄等于网页的修改时间与t的差值。爬虫的目标就是保持仓库中的网页的平均新鲜度尽可能地高，或者平均年龄尽可能地低。

礼貌策略，决定如何避免给被爬网站造成超负荷问题。爬虫获取信息比人快很多，短时间内大量的爬取操作会给网站带来负担，影响被爬网站的正常访问。有人说“爬虫对某些工作有用，但对社会造成了负担”。爬虫给社会带来的负担有：占用了网络资源，造成服务器超负荷，等等。避免给被爬服务器造成过高负荷的方法主要是限制访问的频率，关于“友好”的频率并没有一个标准，传闻有访问日志显示，已知爬虫的爬取间隔在20秒到三四分钟之间。

并行策略，决定如何协调分布式爬虫。分布式地爬取网页为的是提高下载速度，分布式爬虫的目标是最大化下载速度，同时最小化并行操作带来的开销并避免重复下载同一个网页。

# 能够获取网页的长度/修改时间

可以通过给网页服务器发送HEAD指令来使服务器仅仅返回网页的头信息，而不是网页的内容，这个头信息可用于判断是否需要下载网页内容。

使用telnet访问http协议的网页

telnet www.gnu.org 80
HEAD / HTTP/1.1
Host: www.gnu.org
                    <-- 空行

使用openssl访问https协议的网页

openssl s_client -connect stackoverflow.com:443
HEAD / HTTP/1.1
Host: stackoverflow.com
                    <-- 空行

使用curl命令简便访问

    curl -I http://www.example.com

# 能够根据网页的长度/修改时间来决定是否下载该网页

通过储存旧的修改时间和长度信息，后续即可用新数据与旧数据做比较，以决定是否需要重新下载网页内容。以下范例Python代码描述了一个简单的实现方法。

    mtime_in_db = get_mtime(url)
    length_in_db = get_length(url)
    mtime, length = fetch_header(url)
    if mtime != mtime_in_db or length != length_in_db:
        fetch_content(url)

# 了解爬虫的架构

编写一个随意的爬虫用于下载若干个网页，也许是一件轻松的事情，但是如果需要构建一个能够在数周之内下载上亿网页的爬虫，则除了要有良好的爬取策略外，还要有高度优化的架构。网络爬虫是搜索引擎的核心，其核心算法和架构的详情通常被当作商业机密保护起来。一个标准的网络爬虫，其架构包括这些部件：下载器，存储，队列和调度器。

# 了解爬虫身份的标识

通常，爬虫通过http头中的User-Agent域来把它的身份告知网页服务器，但是一些恶意的爬虫不太可能这样做，它很有可能把自己伪装成一个浏览器或者其它知名的搜索引擎。

# 了解深度爬取的方法

互联网上有大量的网页是常规情况下不可见的，对这些网页的访问通常需要对数据库做查询，比如说登录；如果没有指向这些网页的链接，常规的爬虫是下载不到它们的。一些爬虫仅仅检查 <a href="URL"> 中的链接，做深度爬取的爬虫（比如说google）除此之外还会检查网页其它部分的文本。通过JavaScript生成的网页内容，对常规爬虫来说也是不可见的，对这样的网页，类似PhantomJS这样的工具可以处理。



# 正则表达式及其功用

正则表达式也叫“正规表示法”，英文是Regular Expression，用于处理文本。正则表达式兴起于50多年前，如今常见的文本处理工具都支持正则表达式，像grep, sed, awk，等等。书写正则表达式的语法存在多种版本，它们大同小异。

# 能够表示任意字符 (.)

“点”可以表示任意字符，在一般情况下不包括换行符，在Python的re模块中，可以通过re.DOTALL 来使“点”匹配换行符。

# 能够表示任意字母 ([a-zA-Z], [:alpha:])

测试命令：
$ echo {a..z} {A..Z} | sed 's/ //g' | grep --color -E '[[:alpha:]]'
$ echo {a..z} {A..Z} | sed 's/ //g' | grep --color -E '[a-zA-Z]'

# 能够表示任意数字 ([0-9], \d)

grep 命令的扩展正则表达式 (-E 选项)不支持\d 表示法，Perl正则表示法则支持(-P 选项）。

测试命令：
$ echo {0..9} | sed 's/ //g' | grep -E '[0-9]'
$ echo {0..9} | sed 's/ //g' | grep -P '\d'

# 能够表示任意空白字符 (\s)

空白字符常见的有空格、制表符、换行符、回车符，不常见的有垂直制表符\v和换页符\f。

shell测试命令：
$ echo -n $' \t\n\v\f\r' | grep -Ezo '\s' | od -tu1

Python测试代码：
In [20]: re.findall(r'\s', ' \t\n\r\v\f')
Out[20]: [' ', '\t', '\n', '\r', '\x0b', '\x0c']

# 能够表示某个连续范围的字符 ([0-9])

测试命令：
$ echo {0..9} | grep [0-9]
$ echo {0..9} | grep [3-5]
$ echo {0..9} | grep [3-57-9]
$ echo {a..z} | grep [c-h]

# 能够表示一组字符中的一个 [ac134]

测试命令：
$ echo abcd1234 | grep --color [ac134]

# 能够表示不在列表中的字符 [^ac134]

符号 ^ 必须出现在括号中的第一个位置。

测试命令：
$ echo abcd1234 | grep --color [^ac134]

# 了解其它表示单个字符的方法

字符本身        <-- 除了下面的特殊字符之外，字符可以表示其本身
.               <-- Any character
\d              <-- Digit in 0123456789
\D              <-- Non-digit
\w              <-- Word: letters, digits, underscore (_)
\W              <-- Non-word
\t              <-- Tab
\r              <-- Carriage return
\n              <-- New line
\s              <-- Whitespace: space, \t, \r, \n
\S              <-- Non-whitespace
[abc]           <-- a, or b, or c
[a-c]           <-- a, or b, or c
[0-2]           <-- 0, or 1, or 2
[1-3a-cX-Z]     <-- 1, 2, 3, a, b, c, X, Y, Z
[^abc]          <-- Any character except a and b and c
[:upper:]       <-- Upper case letters, [A-Z]
[:lower:]       <-- Lower case letters, [a-z]
[:alpha:]       <-- Alphabetic characters, [a-zA-Z]
[:alnum:]       <-- Alphanumeric characters, [a-zA-Z0-9]
[:digit:]       <-- Digits, [0-9]
[:xdigit:]      <-- Hexadecimal digits, [a-fA-F0-9]
[:punct:]       <-- Punctuation and symbols, [][!"#$%&'()*+,./:;<=>?@\^_`{|}~-]
[:blank:]       <-- Space and tab, [ \t]
[:space:]       <-- All whitespace characters including line breaks, [ \t\r\n\v\f]
[:cntrl:]       <-- Control characters, [\x00-\x1F\x7F]
[:graph:]       <-- Visible characters (i.e. anything except spaces, control characters, etc.), [\x21-\x7E]
[:print:]       <-- Visible characters and spaces (i.e. anything except control characters, etc.), [\x20-\x7E]
[:word:]        <-- Word characters (letters, numbers and underscores), [a-zA-Z0-9_]
[:ascii:]       <-- ASCII characters, [\x00-\x7F]

# 能够表示特殊字符

正则表达式中有一些字符，正常情况下表达的不是其字面的意思，这些就是特殊字符，以下是表示它们的字面意思的方法：

表示字符 ^$.*+?|\{}[]()，可以使用反斜杠做转义，比如 \. \\ \^ \$
表示中括号[...]中的减号，用[abc-]，或者 [-abc]，减号出现在首部或者尾部

# 能够表示一组字符 (xxx|yyy|000)

用小括号把一组字符括起来，起到了标记的作用，使得可以把这些字符当成一个整体对待，方便应用重复表示法，或者方便后面对其引用。

(abc)       <-- 一组连续的字符abc
(aa|bb)     <-- 一组连续的字符ab 或者 bb

是否加小括号，对匹配小括号里面的字符是没有区别的，这两条命令结果一样：
$ echo abcd | grep -E '(abc)'
$ echo abcd | grep -E 'abc'

# 能够表示任意数量的重复 {m}, {m,}, {m,n}, *, +, ?

正则表达式各种表示法只表示单个字符，需要表示重复现象时，要使用数量标识符。以下数量表示法表示前面的一个字符或一组字符重复的次数。

*           <-- 任意次,     c >= 0
+           <-- 至少1次,    c >= 1
?           <-- 0次或者1次, c == 0 || c == 1
{m}         <-- m 次,       c == m
{m,}        <-- 至少m 次,   c >= m
{m,n}       <-- m 次至n 次, c >= m && c <= n

测试命令：
$ echo 7888a | grep --color -E '8*a'
$ echo 7888a | grep --color -E '8+a'
$ echo 7888a | grep --color -E '9*a'
$ echo 7888a | grep --color -E '9+a'
$ echo 7888a | grep --color -E '9?a'
$ echo CPython Python | grep --color -E 'C?Python'
$ echo 7888a | grep --color -E '8{2}a'
$ echo 78a 788a 7888a 78888a | grep --color -E '8{2,}a'
$ echo 78a 788a 7888a 78888a | grep --color -E '8{2,3}a'

对比以下命令的区别，一个标记了组，一个没有：
$ echo 'ab, abb, abbb, abbbb' | grep --color -E 'ab+'
$ echo 'ab, abab, ababab, abababab' | grep --color -E '(ab)+'

默认情况下，数量表示符是最大匹配，好的正则表达式引擎支持用问号 ? 来启用最小匹配

grep命令只支持最大匹配
$ echo aaabababa | grep -E '.*b'

Python的re模块支持最大匹配和最小匹配
In [2]: re.findall('.*?b', 'aaabababa')
Out[2]: ['aaab', 'ab', 'ab']

In [3]: re.findall('.*b', 'aaabababa')
Out[3]: ['aaababab']

# 理解小括号出现的顺序与引用编号的关系

对字符标记了组之后，就可以对其做引用。组的号码从1开始，按左括号出现的顺序计算。

Python代码
In [5]: re.findall(r'((a(b)c)de)fg', 'abcdefg')
Out[5]: [('abcde', 'abc', 'b')]
In [6]: re.sub(r'((a(b)c)de)fg', r'\1', 'abcdefg')
Out[6]: 'abcde'
In [7]: re.sub(r'((a(b)c)de)fg', r'\2', 'abcdefg')
Out[7]: 'abc'
In [8]: re.sub(r'((a(b)c)de)fg', r'\3', 'abcdefg')
Out[8]: 'b'

# 能够表示字符串的首部、尾部，词的左边界、右边界

符号 ^ 出现在表达式的头部，表示字符串的开头；符号 $ 出现在表达式的尾部，表示字符串的结尾；符号 \b 表示词的边界，包括左边界和右边界，出现在左边就表示左边界，出现在右边就表示右边界；符号 \< 和 \> 分别表示左边界和右边界。grep 命令支持 \b, \<, \>；vim支持 \<, \>；Python支持 \b。

^           <-- 字符串的开头
$           <-- 字符串的结尾
\b          <-- 词的边界
\B          <-- 非词边界
\<          <-- 词的左边界
\>          <-- 词的右边界




Python的re模块用法

常用方法：

    re.findall
        返回所有匹配的内容

    re.finditer
        返回一个可迭代的对象，其中的每一个元素都是一个 _sre.SRE_Match 对象

    re.search
    re.match
        search和match在匹配的情况下会返回一个_sre.SRE_Match 对象，
        可以操作这个对象以获取所匹配的内容

    re.split
        按照指定的正则表达式切分字符串，某些场合可用来替代str.split

    re.sub
        In [156]: re.sub('a', 'A', 'a a a')
        Out[156]: 'A A A'
        In [157]: re.sub('a', 'A', 'a a a', count=1)
        Out[157]: 'A a a'
        In [158]: re.sub('a', 'A', 'a a a', count=2)
        Out[158]: 'A A a'
        In [160]: re.sub('A', 'B', 'a A a')
        Out[160]: 'a B a'
        In [161]: re.sub('A', 'B', 'a A a', flags=re.IGNORECASE)
        Out[161]: 'B B B'
        In [174]: re.sub(r',$', r'.', text, flags=re.MULTILINE)
        Out[174]: 'aaaaaaa,aaaaaaa.\nbbbbbbbbbb,bbbbb.\nccccccccccccccc.\nddddddddddddddd.'

    re.compile
        re模块在做正则匹配之前，会把表达式编译成_sre.SRE_Pattern 对象，这是隐式编译，
        不需要用户手动操作。但是有时需要首先手动编译，这样在用同一个表达式重复处理
        时可以提高效率。


常用标记(flag)：

    re.DOTALL
    re.MULTILINE
    re.IGNORECASE
